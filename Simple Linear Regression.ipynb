{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_outliers(df):\n",
    "    \n",
    "    print('Continuious Variables', '\\n')\n",
    "    \n",
    "    for column in df.select_dtypes(include=['int64', 'float64', 'float']):\n",
    "        print(column, df.columns.get_loc(column))\n",
    "        for threshold in [95, 90, 85, 80, 75]:\n",
    "            upper_value = np.percentile(df[column], [threshold])[0]\n",
    "            print('Beyond the lower {}th percentile there are {} outliers'.format(threshold, \n",
    "                len((np.where((df[column] > upper_value))[0]))\n",
    "            ))\n",
    "        if (df[column].nunique() < 20):\n",
    "            print('\\n')\n",
    "            print('Possible Categorical Variable')\n",
    "            print('There are {} unique values'.format(df[column].nunique()))\n",
    "            print(df[column].value_counts())\n",
    "        print('\\n')\n",
    "        \n",
    "        \n",
    "    \n",
    "    print('Categorical Variables', '\\n')\n",
    "    \n",
    "    for column in df.select_dtypes(include='object'):\n",
    "        print(column)\n",
    "        print('There are {} unique values'.format(df[column].nunique()))\n",
    "        if df[column].nunique() < 20:\n",
    "            print(df[column].value_counts())\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the dataset from the Thinkful PostgreSQL database.\n",
    "\n",
    "Investigate the data, and do any necessary data cleaning.\n",
    "Explore the data and find some variables that you think would be useful in predicting house prices.\n",
    "Build your initial model using these features and estimate the parameters using OLS.\n",
    "Spend up to 4 hours on this assignment. You will submit the notebook after the assessment questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'houseprices'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "query1 = '''\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  houseprices\n",
    "'''\n",
    "\n",
    "df = pd.read_sql_query(query1, con=engine)\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Investigate the data, and do any necessary data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_outliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the id variable\n",
    "df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort my features into categorical and continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cats_conts_unsorted(df):\n",
    "     \n",
    "        # Some paramater tuning is no doubt called for at some point. For now these are rough\n",
    "        # values for sorting and we will clean up the rest manually. Better than doing the whole\n",
    "        # thing manually!\n",
    "        \n",
    "    cats = []\n",
    "    conts = []\n",
    "    unsorted = []\n",
    "    \n",
    "    \n",
    "    for column in df.columns:\n",
    "        if df[column].nunique() < 10:\n",
    "            cats.append(column)\n",
    "        \n",
    "        elif df[column].nunique() < 50 or df[column].nunique() <  len(df)/10:\n",
    "            unsorted.append(column)\n",
    "        \n",
    "        else:\n",
    "            conts.append(column)\n",
    "            \n",
    "            # there is some room here to integrate a process for mauallyl assiging categorical\n",
    "            # or continuous to the unsorted columns.\n",
    "            \n",
    "            \n",
    "    print('{} cats'.format(len(cats))\n",
    "         , '\\n', '{} conts'.format(len(conts))\n",
    "         , '\\n', '{} unsorted'.format(len(unsorted))\n",
    "         )\n",
    "    \n",
    "    return cats, conts, unsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats, conts, unsorted = get_cats_conts_unsorted(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.loc[:, unsorted].nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cats = ['mssubclass', 'mosold', 'overallqual', 'totrmsabvgrd', 'exterior2nd', 'exterior1st', 'neighborhood']\n",
    "\n",
    "new_conts =['lotfrontage', 'yearbuilt', 'garageyrblt', 'yearremodadd', 'miscval'\n",
    "            ,'screenporch', 'lowqualfinsf', 'threessnporch', 'bsmtfinsf2', 'enclosedporch', ]\n",
    "\n",
    "for cat in new_cats: \n",
    "    cats.append(cat)\n",
    "\n",
    "for cont in new_conts:\n",
    "    conts.append(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check to make sure our two buckets contain the right number of features\n",
    "len(cats) + len(conts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'saleprice' in conts:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_outliers(df.loc[:, conts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Explore the data and find some variables that you think would be useful in predicting house prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_visualization(df, target, cats, conts):\n",
    "\n",
    "    if target in conts:\n",
    "        \n",
    "        # cont / cont\n",
    "        \n",
    "        map_df = df.loc[:, conts]\n",
    "        map_df.set_index(target)\n",
    "        \n",
    "        plt.figure(figsize=(len(conts)*2, len(conts)*2))\n",
    "        corr_map = map_df.corr()\n",
    "        sns.heatmap(corr_map, square=True, annot=True, linewidths=.5)\n",
    "        \n",
    "        \n",
    "        # cont / cat\n",
    "        plt.figure(figsize=(15, len(cats)*4))\n",
    "\n",
    "        for i, feature in enumerate(cats):\n",
    "            plt.subplot(len(cats), 1, i+1)\n",
    "            sns.barplot(df[feature], df[target])\n",
    "            plt.title(feature)\n",
    "            plt.xlabel('')\n",
    "            plt.xticks(rotation=90)\n",
    "        plt.tight_layout(pad=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    # elif target in cats:\n",
    "    \n",
    "    # need to write second half of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "multivariate_visualization(df, 'saleprice', cats, conts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build your initial model using these features and estimate the parameters using OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
