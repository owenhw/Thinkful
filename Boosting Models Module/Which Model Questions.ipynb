{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using data from the last 20 Olympics, predict the running times of prospective Olympic sprinters\n",
    "\n",
    "    For this I would use a simple linear regression model to begin with. Next I would consider a KNN regression method. \n",
    "\n",
    "### You have more features (columns) than rows in your dataset.\n",
    "    This would This is a good candidate for a KNN model. After that initial pass would try a boosting method to check the feature importance and see if we can reduce dimensionality and noise. \n",
    "\n",
    "### Identify the most important characteristic for predicting the likelihood of being jailed before age 20.\n",
    "    I'd begin with a boosing classifier model to evalute feature importance. A decision tree would be a good visualization for communicating our results. \n",
    "\n",
    "### Implement a filter to highlight emails that might be important to the recipient.\n",
    "    Simple calssification problem. Will the user open this or not. Are we flagging these emails or displaying only the ones we think the user should see? Either way we should consider this as we ballance precision and recall. A decision tree followed by a random forest would be my first approach. From there I would considder KNN and SVM classifiers.\n",
    "    \n",
    "\n",
    "### You have more than 1,000 features.\n",
    "    Begin with a common sense first pass and see how many of these features are actually related to my target variable. Then test that sample set out with a simple model and see if we have any predictive power. From there re-iterare and refine if waranted else revisit feature selection.  \n",
    "\n",
    "\n",
    "### Predict whether someone who adds items to their cart on a website will purchase the items.\n",
    "    I'd begin with a simple decision tree and see what the accuracy looks like. From there I would probably try a random forest. \n",
    "\n",
    "### Your dataset dimensions are 982400x500.\n",
    "    With almost a million rows it will become very important to manage computational resources. In this case I would begin with feature reduction. \n",
    "    \n",
    "### Identify faces in an image.\n",
    "    So far we have not covered any methods for image analysis. The main challange here is feature extraction. There are some good resources that cover the basics with sklearn.\n",
    "\n",
    "### Predict which of three flavors of ice cream will be most popular with boys versus girls.\n",
    "    Firstly I think this question needs to be reframed. We have to rand the prefreence of the ice creams for boys and girls and find the one with the biggest gap in favor of boys. This way we can create a regression problem to predict the score in either direction centered on 0.\n",
    "    \n",
    "    Then I would try out several regression models and see how my performance compares. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
