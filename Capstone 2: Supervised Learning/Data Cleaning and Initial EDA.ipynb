{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owen/bin/anaconda3/envs/geo_env/lib/python3.8/site-packages/geopandas/_compat.py:84: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.8.1-CAPI-1.13.3). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nulls(df):\n",
    "    \n",
    "    return df.isnull().sum()*100/df.isnull().isnull().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we know about the data already\n",
    "\n",
    "I merged the data from the indego website https://www.rideindego.com/about/data/\n",
    "\n",
    "The data ranges from the start of the program in _start_date_ 2015 through to _end date_2020_. Per the website above trips shorter than 1 minute have been removed and trip length has been capped at 24 hours. I will keep this in mind as I consider outliers. \n",
    "\n",
    "We do not have any information other than start and end points, about the routes that riders took.\n",
    "\n",
    "We also must consider that this is a biased dataset. These data represents a specific population of bikers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owen/bin/anaconda3/envs/geo_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (6,7,9,10,11,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(r'data/indego/indego-trips-all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type errors let us know that we may have some problems with missing or improperly typed data. \n",
    "# We already know this from merging our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop the unique identifier\n",
    "df.drop('trip_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode trip type\n",
    "mask = df['trip_route_category'] == 'One Way'\n",
    "df.loc[mask, 'trip_route_category'] = 0\n",
    "\n",
    "mask = df['trip_route_category'] == 'Round Trip'\n",
    "df.loc[mask, 'trip_route_category'] = 1\n",
    "\n",
    "df['trip_route_category'] = pd.to_numeric(df['trip_route_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indego30        2860633\n",
       "Walk-up          365475\n",
       "Indego365        299087\n",
       "Day Pass         215584\n",
       "IndegoFlex        33713\n",
       "One Day Pass       6767\n",
       "Two Day Pass       1603\n",
       "Name: passholder_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how ballanced our level are in some of our categorical variables\n",
    "df['passholder_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.000     2860504\n",
       "0.000       362334\n",
       "365.000     332819\n",
       "1.000       225500\n",
       "2.000         1619\n",
       "180.000        114\n",
       "Name: plan_duration, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['plan_duration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.000     2860499\n",
       "365.000        134\n",
       "Name: plan_duration, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['passholder_type'] == 'Indego30']['plan_duration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We propably only need one of these plan type variables, both have decently distributed levels\n",
    "df.drop('passholder_type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0             0.000\n",
       "duration               0.000\n",
       "start_time             0.000\n",
       "end_time               0.000\n",
       "start_station_id      63.496\n",
       "start_lat              0.017\n",
       "start_lon              0.017\n",
       "end_station_id        63.496\n",
       "end_lat                0.828\n",
       "end_lon                0.828\n",
       "bike_id                0.024\n",
       "plan_duration          0.000\n",
       "trip_route_category    0.000\n",
       "start_station         36.504\n",
       "end_station           36.504\n",
       "bike_type             62.456\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First the location data\n",
    "# Luckily the problem is missing values in a small proportion of columns\n",
    " \n",
    "cols = ['start_lat', 'start_lon', 'end_lat', 'end_lon']\n",
    "\n",
    "for col in cols:\n",
    "    df[df[col] == r'\\N'] = np.nan\n",
    "    \n",
    "    df[col] = pd.to_numeric(df[col])\n",
    "\n",
    "# entries that have 0 listed for both end coordinates\n",
    "index = df[df['end_lat'] == 0].index\n",
    "df.drop(index, inplace=True)\n",
    "\n",
    "# entries that have 0 listed for both start coordinates \n",
    "index = df[df['start_lat'] == 0].index\n",
    "df.drop(index, inplace=True)\n",
    "\n",
    "#Two entries have negative latitude values for the start and end, they can be retrieved\n",
    "mask = df['start_lat'] < 0\n",
    "df.loc[mask, 'start_lat'] = df.loc[mask, 'start_lat'] * -1\n",
    "\n",
    "\n",
    "# Three entries where only the end latitude is negative\n",
    "mask = df['end_lat'] < 0\n",
    "df.loc[mask, 'end_lat'] = df.loc[mask, 'end_lat'] *-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The formatting on this column changed part way through the dataset\n",
    "# Fill into one column from the other\n",
    "mask = df['start_station'].isna()\n",
    "df.loc[mask, 'start_station'] = df['start_station_id']\n",
    "\n",
    "# and for the end stations\n",
    "mask = df['end_station'].isna()\n",
    "df.loc[mask, 'end_station'] = df['end_station_id']\n",
    "\n",
    "# drop the other columns\n",
    "df.drop(['start_station_id', 'end_station_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bike type column\n",
    "# This column is introduced in 2018-q3 report. This is also when a second bike type was introduced\n",
    "# Therefore we can assume that all the trips before that were on standard bikes. Nulls only appear for this \n",
    "# time before there were electric bikes so it is safe to fill all of them\n",
    "df['bike_type'] = df['bike_type'].fillna('standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bike_id values\n",
    "# Here there are just a few badly formated values that are easily retrieved\n",
    "index = df[df['bike_id'] == '03556A'].index\n",
    "df.loc[index, 'bike_id'] = 3556\n",
    "\n",
    "# 4 values asking to be deleted; we oblidge\n",
    "index = df[df['bike_id'] == 'delete me'].index\n",
    "df.drop(index, inplace=True)\n",
    "\n",
    "df['bike_id'] = pd.to_numeric(df['bike_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3552275\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are a small number of trips that appear to be duplicates\n",
    "df[['start_time', 'bike_id', 'start_station']].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(['start_time', 'bike_id', 'start_station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3584862\n",
       "True         214\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What about trips that end at the same time at the same station?\n",
    "df[['end_time', 'bike_id', 'end_station']].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(['end_time', 'bike_id', 'end_station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3584862\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0.000\n",
       "duration              0.000\n",
       "start_time            0.000\n",
       "end_time              0.000\n",
       "start_lat             0.016\n",
       "start_lon             0.016\n",
       "end_lat               0.872\n",
       "end_lon               0.872\n",
       "bike_id               0.025\n",
       "plan_duration         0.000\n",
       "trip_route_category   0.000\n",
       "start_station         0.000\n",
       "end_station           0.000\n",
       "bike_type             0.000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0.000\n",
       "duration              0.000\n",
       "start_time            0.000\n",
       "end_time              0.000\n",
       "start_lat             0.000\n",
       "start_lon             0.000\n",
       "end_lat               0.000\n",
       "end_lon               0.000\n",
       "bike_id               0.000\n",
       "plan_duration         0.000\n",
       "trip_route_category   0.000\n",
       "start_station         0.000\n",
       "end_station           0.000\n",
       "bike_type             0.000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of data retained after cleaning:  93.90356121247817\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of data retained after cleaning: ', len(df)/len(raw_data) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Timeseries and Location Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next the timestamp values\n",
    "df['start_time'] = pd.to_datetime(df['start_time'])\n",
    "df['end_time'] = pd.to_datetime(df['end_time'])\n",
    "\n",
    "# Simply recalulate the duration\n",
    "# The result will be in minutes because that is what all of our start and stop times are rounded to\n",
    "df['duration'] = (pd.to_timedelta(df['end_time'] - df['start_time']).dt.seconds / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_geometry'] = [Point(xy) for xy in zip(df['start_lon'], df['start_lat'])]\n",
    "\n",
    "df['end_geometry'] = [Point(xy) for xy in zip(df['end_lon'], df['end_lat'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "First we should recall that trip duration has been treated already. While the data contain no entries greater than 24 hours as expected there are still some trips with a duration less than one minute. I will remove those as that is one of the assumptions of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   3552275.000\n",
       "mean         21.542\n",
       "std          53.186\n",
       "min           0.000\n",
       "25%           7.650\n",
       "50%          12.000\n",
       "75%          20.000\n",
       "max        1439.000\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['duration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 2488 observations, 0.0% of the data\n"
     ]
    }
   ],
   "source": [
    "index = df[df['duration'] < 1].index\n",
    "print('Dropping {} observations, {}% of the data'.format(len(index), round(len(index)/len(df), 2)))\n",
    "df.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing notes on data cleaning\n",
    "\n",
    "Overall the vast majority of the data was retained. However still more of it might be retained with more metadata or more cleaning. \n",
    "\n",
    "The differences between the end coordinates for trips with the same end station should be considered. Perhaps these differences arise from abnormal trips that are outliers in some way?\n",
    "\n",
    "Lastly issues like duplicate trips or extrememly short trips could be errors in the logging system or user errors. These appear to make up only a small portion of the data but it is still worth considering how to better account for these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdf = df.loc[:, ['duration', 'start_station', 'trip_route_category', 'start_time']]\n",
    "\n",
    "indf = df.loc[:, ['duration', 'end_station', 'trip_route_category', 'end_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "indf['flow'] = 1\n",
    "outdf['flow'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "indf = indf.rename(columns={'duration' : 'incoming_duration', 'end_station' : 'station', 'end_time' : 'datetime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf = outdf.rename(columns={'duration' : 'outgoing_duration', 'start_station' : 'station', 'start_time' : 'datetime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stapled = pd.concat([indf, outdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of the stations\n",
    "stations = stapled['station'].unique()\n",
    "\n",
    "# create a dict to create and hold the dataframes\n",
    "station_frames = {}\n",
    "\n",
    "# loop through the data for each station\n",
    "for station in stations:\n",
    "    \n",
    "    #select the data for that station\n",
    "    mask = stapled['station'] == station\n",
    "    small = stapled.loc[mask, :]\n",
    "    \n",
    "    # aggregate it\n",
    "    small.set_index('datetime', inplace=True)\n",
    "    grouped = small.resample('H').agg({'flow' : 'sum'\n",
    "                         , 'incoming_duration' : 'mean'\n",
    "                        , 'outgoing_duration' : 'mean'\n",
    "                        , 'trip_route_category' : 'mean'})\n",
    "    \n",
    "    # preserves the int type better than .agg('mean')\n",
    "    grouped['station'] = station\n",
    "    \n",
    "    station_frames[station] = grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified = pd.DataFrame()\n",
    "for station in stations:\n",
    "    unified = pd.concat([unified, station_frames[station]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unified.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulls can safely be filled with 0\n",
    "unified.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified['ds'] = unified.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploritory Data Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified.plot('ds', 'flow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_3056 = unified[unified['station']  == 3056].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot('ds', 'flow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for key in station_frames:\n",
    "    value = station_frames[key]\n",
    "    value['hour'] = value.index.hour\n",
    "    value.groupby('hour')['flow'].agg('mean').plot()\n",
    "plt.xticks(np.arange(24))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
