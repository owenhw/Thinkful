{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "#import geopandas as gpd\n",
    "#from shapely.geometry import Point, Polygon\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nulls(df):\n",
    "    \n",
    "    return df.isnull().sum()*100/df.isnull().isnull().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we know about the data already\n",
    "\n",
    "I merged the data from the indego website https://www.rideindego.com/about/data/\n",
    "\n",
    "The data ranges from the start of the program in _start_date_ 2015 through to _end date_2020_. Per the website above trips shorter than 1 minute have been removed and trip length has been capped at 24 hours. I will keep this in mind as I consider outliers. \n",
    "\n",
    "We do not have any information other than start and end points, about the routes that riders took.\n",
    "\n",
    "We also must consider that this is a biased dataset. These data represents a specific population of bikers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owen/bin/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (5,6,8,9,10,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('indego-trips-all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type errors let us know that we may have some problems with missing or improperly typed data. \n",
    "# We already know this from merging our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trip_id', 'duration', 'start_time', 'end_time', 'start_station_id',\n",
       "       'start_lat', 'start_lon', 'end_station_id', 'end_lat', 'end_lon',\n",
       "       'bike_id', 'plan_duration', 'trip_route_category', 'passholder_type',\n",
       "       'start_station', 'end_station', 'bike_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only retain a handful of the columns\n",
    "\n",
    "cols = ['duration', 'start_time', 'end_time', 'start_station_id',\n",
    "       'end_station_id', 'trip_route_category', 'start_station', 'end_station',]\n",
    "\n",
    "df = raw_data.loc[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check how ballanced our level are in some of our categorical variables\n",
    "df['passholder_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['plan_duration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['passholder_type'] == 'Indego30']['plan_duration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We propably only need one of these plan type variables, both have decently distributed levels\n",
    "df.drop('passholder_type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First the location data\n",
    "# Luckily the problem is missing values in a small proportion of columns\n",
    " \n",
    "cols = ['start_lat', 'start_lon', 'end_lat', 'end_lon']\n",
    "\n",
    "for col in cols:\n",
    "    df[df[col] == r'\\N'] = np.nan\n",
    "    \n",
    "    df[col] = pd.to_numeric(df[col])\n",
    "\n",
    "# entries that have 0 listed for both end coordinates\n",
    "index = df[df['end_lat'] == 0].index\n",
    "df.drop(index, inplace=True)\n",
    "\n",
    "# entries that have 0 listed for both start coordinates \n",
    "index = df[df['start_lat'] == 0].index\n",
    "df.drop(index, inplace=True)\n",
    "\n",
    "#Two entries have negative latitude values for the start and end, they can be retrieved\n",
    "mask = df['start_lat'] < 0\n",
    "df.loc[mask, 'start_lat'] = df.loc[mask, 'start_lat'] * -1\n",
    "\n",
    "\n",
    "# Three entries where only the end latitude is negative\n",
    "mask = df['end_lat'] < 0\n",
    "df.loc[mask, 'end_lat'] = df.loc[mask, 'end_lat'] *-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The formatting on this column changed part way through the dataset\n",
    "# Fill into one column from the other\n",
    "mask = df['start_station'].isna()\n",
    "df.loc[mask, 'start_station'] = df['start_station_id']\n",
    "\n",
    "# and for the end stations\n",
    "mask = df['end_station'].isna()\n",
    "df.loc[mask, 'end_station'] = df['end_station_id']\n",
    "\n",
    "# drop the other columns\n",
    "df.drop(['start_station_id', 'end_station_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bike type column\n",
    "# This column is introduced in 2018-q3 report. This is also when a second bike type was introduced\n",
    "# Therefore we can assume that all the trips before that were on standard bikes. Nulls only appear for this \n",
    "# time before there were electric bikes so it is safe to fill all of them\n",
    "df['bike_type'] = df['bike_type'].fillna('standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bike_id values\n",
    "# Here there are just a few badly formated values that are easily retrieved\n",
    "index = df[df['bike_id'] == '03556A'].index\n",
    "df.loc[index, 'bike_id'] = 3556\n",
    "\n",
    "# 4 values asking to be deleted; we oblidge\n",
    "index = df[df['bike_id'] == 'delete me'].index\n",
    "df.drop(index, inplace=True)\n",
    "\n",
    "df['bike_id'] = pd.to_numeric(df['bike_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# There are a small number of trips that appear to be duplicates\n",
    "df[['start_time', 'bike_id', 'start_station']].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(['start_time', 'bike_id', 'start_station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about trips that end at the same time at the same station?\n",
    "df[['end_time', 'bike_id', 'end_station']].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(['end_time', 'bike_id', 'end_station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of data retained after cleaning: ', len(df)/len(raw_data) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Timeseries and Location Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next the timestamp values\n",
    "df['start_time'] = pd.to_datetime(df['start_time'])\n",
    "df['end_time'] = pd.to_datetime(df['end_time'])\n",
    "\n",
    "# Simply recalulate the duration\n",
    "# The result will be in minutes because that is what all of our start and stop times are rounded to\n",
    "df['duration'] = (pd.to_timedelta(df['end_time'] - df['start_time']).dt.seconds / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_geometry'] = [Point(xy) for xy in zip(df['start_lon'], df['start_lat'])]\n",
    "\n",
    "df['end_geometry'] = [Point(xy) for xy in zip(df['end_lon'], df['end_lat'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "First we should recall that trip duration has been treated already. While the data contain no entries greater than 24 hours as expected there are still some trips with a duration less than one minute. I will remove those as that is one of the assumptions of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['duration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = df[df['duration'] < 1].index\n",
    "print('Dropping {} observations, {}% of the data'.format(len(index), round(len(index)/len(df), 2)))\n",
    "df.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing notes on data cleaning\n",
    "\n",
    "Overall the vast majority of the data was retained. However still more of it might be retained with more metadata or more cleaning. \n",
    "\n",
    "The differences between the end coordinates for trips with the same end station should be considered. Perhaps these differences arise from abnormal trips that are outliers in some way?\n",
    "\n",
    "Lastly issues like duplicate trips or extrememly short trips could be errors in the logging system or user errors. These appear to make up only a small portion of the data but it is still worth considering how to better account for these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploritory Data Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['trip_route_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What is the average tirp duration for each category of trip?\n",
    "df.groupby(by='trip_route_category')['duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_station'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = ~df['end_station'].isin(df['start_station'])\n",
    "df.loc[mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['end_station'] == 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all of the stations connect with the others via at least one trip, one trip a year, a month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "combs = combinations([df['start_station'], df['end_station']], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration could likely benefit from a natural log transormation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(df['duration'])\n",
    "plt.title('Histogram of Trip Duration')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(np.log(df['duration']))\n",
    "plt.title('Histogram of Log Normal Trip Duration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by='start_station').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(df\n",
    "                      , crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_map = gpd.read_file(r'/home/owen/Jupyter/Capstone 2: Supervised Learning/Zipcodes_Poly-shp/Zipcodes_Poly.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "ax = plt.subplot(1,1,1)\n",
    "gdf[:50000].plot(ax=ax)\n",
    "zip_map.plot(alpha=.4, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_map.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods = gpd.read_file(r'Neighborhoods_Philadelphia.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods = neighborhoods.to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods.cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdf = gdf[1000000:1050000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods.contains(sgdf.geometry)neighborhoods.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "ax = plt.subplot(1,1,1)\n",
    "neighborhoods.plot(alpha=.4, color='grey', ax=ax)\n",
    "sgdf.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = neighborhoods.cx[-75.224:39.890, -75.130:39.992]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[['start_lon','start_lat']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
