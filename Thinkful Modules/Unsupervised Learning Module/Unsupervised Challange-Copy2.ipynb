{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "- better understand the use of unsupervised learning techniques\n",
    "- use a variety of methods and models\n",
    "- explore hyperparamater tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "Here I will use the [FIFA2019 dataset](https://www.kaggle.com/karangadiya/fifa19) from Kaggle. I will import it from Thinkful's postgreSQL server.\n",
    "\n",
    "### Import Libraries and Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN, MeanShift\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn import metrics\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n",
    "    \n",
    "def print_nulls(df):\n",
    "    out = pd.Series({'Column': 'Percentage of nulls', '-----' : '-----'}\n",
    "                   ).append(df.isnull().sum()*100/df.isnull().isnull().count())\n",
    "   \n",
    "    return print_full(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_boxplot(df):\n",
    "    '''\n",
    "    Accepts only numerical columns;\n",
    "    use a maks.\n",
    "    '''\n",
    "    dim = df.shape[1]\n",
    "    plt.figure(figsize=(20, dim*5))\n",
    "    \n",
    "    # iterate through the columns\n",
    "    for i, column in enumerate(df.columns):\n",
    "        \n",
    "        # plot a histogram\n",
    "        plt.subplot(dim, 2, (i+1)*2-1)\n",
    "        plt.hist(df[column])\n",
    "        plt.ylabel(column, size='xx-large')\n",
    "        \n",
    "        # plot a boxplot\n",
    "        plt.subplot(dim, 2, (i+1)*2)\n",
    "        plt.boxplot(df[column], whis=[2.5, 97.5]) # boxplot will show outliers beyond the inner 90th percentile\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'fifa19'\n",
    "\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "    \n",
    "query1='''\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    fifa19\n",
    "'''\n",
    "    \n",
    "    \n",
    "df = pd.read_sql_query(query1, con=engine)\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make column names lowercase for ease and consistency\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Drop some columns of the columns\n",
    "'''\n",
    "The first two lines of columns are unneeded such as links to images.\n",
    "The second two lines are position scores.\n",
    "\n",
    "All keepers are missing values for these columns. It may be better to seperate out the columns but\n",
    "I also suspect that these are not valuable features are are adding noise to the model.\n",
    "To test this I'm dropping them in this iteration of my modeling\n",
    "'''\n",
    "df.drop(['ID', 'Name',  'Photo',  'Flag', \n",
    "       'Potential',  'Club Logo', 'Real Face', 'Jersey Number', 'Loaned From', 'Contract Valid Until'\n",
    "         \n",
    "         , 'LS', 'ST', 'RS', 'LW', 'LF', 'CF', 'RF', 'RW','LAM', 'CAM', 'RAM', 'LM', 'LCM', 'CM', 'RCM'\n",
    "         , 'RM', 'LWB', 'LDM','CDM', 'RDM', 'RWB', 'LB', 'LCB', 'CB', 'RCB', 'RB',], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Make column names lowercase for ease and consistency\n",
    "df.columns= df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['joined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['joined'].astype('datetime64').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply derived functions for this dataset \n",
    "\n",
    "def clean(df):\n",
    "    # Drop the small portion of remaining nulls\n",
    "    df = df.dropna().copy() \n",
    "    \n",
    "    # Values for wage and value need to be converted from strings to numerical \n",
    "\n",
    "    df['wage'] = df['wage'].apply(lambda x: int(str(x).replace('€', '').replace('K', '')\n",
    "                                               ) * 1000 if 'K' in str(x) else x)\n",
    "\n",
    "    df['wage'] = df['wage'].apply(lambda x: int(str(x).replace('€', '').replace('M', '')\n",
    "                                               ) * 1000000 if 'M' in str(x) else x)\n",
    "\n",
    "    df['wage'] = df['wage'].apply(lambda x: 0 if str(x) == '€0' else x)\n",
    "\n",
    "\n",
    "\n",
    "    df['value'] = df['value'].apply(lambda x: float(str(x).replace('€', '').replace('K', '')\n",
    "                                               ) * 1000 if 'K' in str(x) else x)\n",
    "\n",
    "    df['value'] = df['value'].apply(lambda x: float(str(x).replace('€', '').replace('M', '')\n",
    "                                               ) * 1000000 if 'M' in str(x) else x)\n",
    "\n",
    "    df['value'] = df['value'].apply(lambda x: 0 if str(x) == '€0' else x)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    The release clause value presents a difficulty for filling. Presumably these are players that do \n",
    "    not have a release clause. As shown above this includes players at both the high and low end of the\n",
    "    pay scale. Filling these nulls with 0 makes no sense and infinity is not supported by algorithms\n",
    "    despite being logically closer. Perhaps turning this into a categorical variable would help?\n",
    "    Luckily this is not a regression problem where the value would be more important.\n",
    "    For now I will fill these values with 0 because all I am trying to achieve right now is clustering\n",
    "    and this will give these observations a valid common value.\n",
    "    '''\n",
    "    \n",
    "    df['release clause'] = df['release clause'].fillna(0)\n",
    "    \n",
    "    df['release clause'] = df['release clause'].apply(lambda x: float(str(x).replace('€', '').replace('K', '')\n",
    "                                               ) * 1000 if 'K' in str(x) else x)\n",
    "\n",
    "    df['release clause'] = df['release clause'].apply(lambda x: float(str(x).replace('€', '').replace('M', '')\n",
    "                                               ) * 1000000 if 'M' in str(x) else x)\n",
    "\n",
    "    df['release clause'] = df['release clause'].apply(lambda x: 0 if str(x) == '€0' else x)\n",
    "    \n",
    "    \n",
    "    # Convert height to int\n",
    "    df['height'] = df['height'].apply(lambda x : str(x).split('\\''))\n",
    "\n",
    "    df['height'] = df['height'].apply(lambda x : (int(x[0]) * 12) + int(x[1]))\n",
    "    \n",
    "    \n",
    "    # Convert weight to int\n",
    "    df['weight'] = df['weight'].apply(lambda x : int(str(x).strip('lbs')))\n",
    "    \n",
    "    \n",
    "    # Encode perferred foot as numerical\n",
    "    df['right preferred'] = df['preferred foot'].apply(lambda x : 1 if str(x) == 'Right'\n",
    "                                                  else 0)\n",
    "    df.drop('preferred foot', axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    # For the fielders their position scores need to be cleaned and typed properly\n",
    "    '''\n",
    "    These position scores lead to some unstable solutions. In this pass they are eliminated\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    for col in ['ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram',\n",
    "       'lm', 'lcm', 'cm', 'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb',\n",
    "       'lcb', 'cb', 'rcb', 'rb']:\n",
    "    \n",
    "        if col in df.columns:\n",
    "\n",
    "            df[col] = df[col].apply(lambda x: sum([int(i) for i in str(x).split('+')]))\n",
    "        \n",
    "    '''\n",
    "    Work rate is highliy subjective and may cause unstable solutions.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Seperate and encode the workrate values as ordinal\n",
    "    #df['defense work rate'] = df['work rate'].apply(lambda x: 3 if (str(x).split('/ '))[1] == 'High' else\n",
    "    #                                          (2 if (str(x).split('/ '))[1] == 'Medium' else 1))\n",
    "\n",
    "    #df['offense work rate'] = df['work rate'].apply(lambda x: 3 if (str(x).split('/ '))[0] == 'High' else\n",
    "    #                                               (2 if (str(x).split('/ '))[0] == 'Medium' else 1))\n",
    "    \n",
    "    df.drop('work rate', axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Log transform release cluase and value\n",
    "    '''\n",
    "    Release clause value and wage all are heavily skewed left. Release clause and value are benefit\n",
    "    greatly from a log normal transformation and become roughly normal.\n",
    "    \n",
    "    Wage does not normalize as easiliy. For this pass I will drop it because is strongly correlated with \n",
    "    value (.85) so most of that infromation will be retained.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df['release clause'] = df['release clause'].apply(lambda x: np.log(x) if x !=0 else np.log(x+1))\n",
    "    \n",
    "    df['value'] = df['value'].apply(lambda x: np.log(x) if x !=0 else np.log(x+1))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Drop some categorical variables\n",
    "    \n",
    "    '''\n",
    "    Club and Nationality in particular add too many dimensions. \n",
    "    \n",
    "    \n",
    "    '''\n",
    "\n",
    "    #df.drop('position', axis=1, inplace=True)\n",
    "\n",
    "    df.drop('body type', axis=1, inplace=True)\n",
    "\n",
    "    df.drop('club', axis=1, inplace=True)\n",
    "\n",
    "    df.drop('nationality', axis=1, inplace=True)\n",
    "    \n",
    "    df.drop('joined', axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body type'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepers = df[df['position'] == 'GK'].copy()\n",
    "\n",
    "fielders = df[df['position'] != 'GK'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_hist_boxplot(keepers.select_dtypes(include='number'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepers.drop('skill moves', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepers['value'] = keepers['value'].apply(lambda x: np.log(x) if x !=0 else np.log(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepers['release clause'] = keepers['release clause'].apply(lambda x: np.log(x) if x !=0 else np.log(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepers.drop('wage', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(keepers['international reputation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pt.fit_transform(keepers.drop('position', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    plt.hist(X[:, i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to print a 2D PCA\n",
    "\n",
    "def pca_2d(df):\n",
    "    # initalize the module and get the components\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_components = pca.fit_transform(df)\n",
    "    \n",
    "    # plot the 2D representation\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    plt.scatter(pca_components[:, 0], pca_components[:, 1])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return pca_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['release clause'] = df['release clause'].apply(lambda x: np.log(x) if x !=0 else np.log(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['position'], prefix='position')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['wage', 'position'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pt.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    plt.hist(X[:, i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "scipy.stats.describe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to print a UMAP\n",
    "\n",
    "def umap_2d(df):\n",
    "    umap_components = umap.UMAP(n_neighbors=200,\n",
    "                      min_dist=.5,\n",
    "                      metric='cosine').fit_transform(df)\n",
    "\n",
    "    \n",
    "    # plot the 2D representation\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    plt.scatter(umap_components[:, 0], umap_components[:, 1])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return umap_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elbow Method\n",
    "seed = 0\n",
    "elbow = dict()\n",
    "for k in range(2,50):\n",
    "    estimator = KMeans(n_clusters = k,random_state=seed)\n",
    "    res = estimator.fit_predict(X)\n",
    "    inertia = estimator.inertia_\n",
    "    elbow[k] = inertia\n",
    "    \n",
    "elbow_df = pd.Series(elbow)\n",
    "ax = elbow_df.plot(title = 'Elbow Method')\n",
    "ax.set_xlabel('Number of clusters')\n",
    "ax.set_ylabel('Inertia')\n",
    "#plt.plot(3,elbow_df[3],'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fielders['position'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elbow Method\n",
    "seed = 0\n",
    "elbow = dict()\n",
    "for k in range(2,5):\n",
    "    estimator = KMeans(n_clusters = k,random_state=seed)\n",
    "    res = estimator.fit_predict(X)\n",
    "    inertia = estimator.inertia_\n",
    "    elbow[k] = inertia\n",
    "    \n",
    "elbow_df = pd.Series(elbow)\n",
    "ax = elbow_df.plot(title = 'Elbow Method')\n",
    "ax.set_xlabel('Number of clusters')\n",
    "ax.set_ylabel('Inertia')\n",
    "#plt.plot(3,elbow_df[3],'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KMeans(n_clusters = 3,random_state=seed)\n",
    "res = estimator.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_components.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_components = pca.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'blue', 'black']\n",
    "\n",
    "for i in range(pca_components.shape[0]):\n",
    "    plt.scatter(pca_components[i, 0], pca_components[i, 1], color=colors[int(res[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['cluster'] == 0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['cluster'] == 0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['cluster'] == 2].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elbow Method\n",
    "seed = 0\n",
    "elbow = dict()\n",
    "for k in range(2,5):\n",
    "    estimator = KMeans(n_clusters = k,random_state=seed)\n",
    "    res = estimator.fit_predict(X)\n",
    "    inertia = estimator.inertia_\n",
    "    elbow[k] = inertia\n",
    "    \n",
    "elbow_df = pd.Series(elbow)\n",
    "ax = elbow_df.plot(title = 'Elbow Method')\n",
    "ax.set_xlabel('Number of clusters')\n",
    "ax.set_ylabel('Inertia')\n",
    "#plt.plot(3,elbow_df[3],'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KMeans(n_clusters = 3,random_state=seed)\n",
    "res = estimator.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_components.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_components = pca.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'blue', 'black']\n",
    "\n",
    "for i in range(pca_components.shape[0]):\n",
    "    plt.scatter(pca_components[i, 0], pca_components[i, 1], color=colors[int(res[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['cluster'] == 0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['cluster'] == 0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['cluster'] == 2].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fielders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
